#!/usr/bin/python

# Copyright 2012 Erik-Jan van Baaren (erikjan@gmail.com)
# This tool is released as part of the python package ESClient which can be found on PyPI.org.

import esclient
import argparse
import sys
import json
import sys
import time

parser = argparse.ArgumentParser(description="Import a dump from esdump, optionally overriding the index name and/or document type." +
" This tool will auto-detect the file type (plain, gz, bzip2) based on the file extension.\n" +
" !! Please note that you have to create the appropriate mappings yourself !!")

parser.add_argument('--url', '-u', required=True, help="The full URL to the ElasticSearch server, including port")
parser.add_argument('--file', '-f', required=False, help="The input file to read from. By default esimport will read from stdin")
parser.add_argument('--index', '-i', required=False, help="Override the index where data will end up")
parser.add_argument('--doctype', '-t', required=False, help="Override the document type")
parser.add_argument('--mode', '-m', default="bulk",required=False, help="Mode of indexing(use single/bulk)")
parser.add_argument('--bulk_size', '-s', default=1000,required=False, help="Size of bulk indexing")

arguments = parser.parse_args()

es = esclient.ESClient(arguments.url)

if arguments.file:
    file_lower = arguments.file.lower()
    if file_lower.endswith(".gz"):
        import gzip
        f = gzip.open(arguments.file, "rb")
    elif file_lower.endswith(".bz2"):
        import bz2
        f = bz2.BZ2File(arguments.file, "rb")
    else:
        f = open(arguments.file, "r")
else:
    # use stdin as a file
    f = sys.stdin

counter = 0
bulk_count=0
if arguments.mode == "bulk":
  print "Started %s importing of %s with size %s" % (arguments.mode,arguments.file,arguments.bulk_size)
else:
  print "Started %s importing of %s" % (arguments.mode,arguments.file)
startTime = int(round(time.time() * 1000))
for doc in f:
    doc = json.loads(doc)
    
    if arguments.index:
        index = arguments.index
    else:
        index = doc["_index"]
    
    if arguments.doctype:
        doctype = arguments.doctype
    else:
        doctype = doc["_type"]
    try:    
        parent = doc["_parent"]
    except KeyError:
        parent = None

    try:
        routing = doc["_routing"]
    except KeyError:
        routing = None
    
    if arguments.mode == "single":
	if not es.index(index, doctype, doc["_source"], docid=doc["_id"], parent=parent, routing=routing):
	  sys.stderr.write("Error occured while indexing documents, stopping!\n");
	  sys.exit(1)
	else:
	  counter += 1
    else:
	es.bulk_index(index, doctype, doc["_source"], docid=doc["_id"])
	counter += 1	
	bulk_count+=1
	if (bulk_count == int(arguments.bulk_size)):
	    es.bulk_push();
	    sys.stdout.write(".")
	    sys.stdout.flush()
	    bulk_count=0

f.close()

if arguments.mode == "bulk":
    es.bulk_push();
    sys.stdout.write(".")
    sys.stdout.flush()
endTime = int(round(time.time() * 1000))
print "\nIndexing of %d documents completed" % (counter)
print "Elapsed time: %d ms" % (endTime-startTime)
